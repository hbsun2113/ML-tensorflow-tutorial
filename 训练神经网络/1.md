##最佳做法
丢弃正则化

这是称为丢弃的另一种形式的正则化，可用于神经网络。其工作原理是，在梯度下降法的每一步中随机丢弃一些网络单元。丢弃得越多，正则化效果就越强：

0.0 = 无丢弃正则化。

1.0 = 丢弃所有内容。模型学不到任何规律。

0.0 和 1.0 之间的值更有用。

##playground
1. [几种标准化方法](https://colab.research.google.com/notebooks/mlcc/improving_neural_net_performance.ipynb?hl=zh-cn#scrollTo=baKZa6MEKxlK)
   
