##对非线性规律进行编码
特征组合是指通过将两个或多个输入特征**相乘**来对特征空间中的非线性规律进行编码的合成特征。

在实践中，机器学习模型很少会组合连续特征。不过，机器学习模型却经常组合独热特征矢量(one hot)，将独热特征矢量的特征组合视为逻辑连接。

对大规模数据集使用特征组合是学习高度复杂模型的一种有效策略。神经网络可提供另一种策略。(自己的理解：神经网络之所以比其他模型更加优越，是因为它更适用于大规模数据啊。我的疑问是：为什么神经网络更适用于大规模数据呢？)


##Playground
1.在特征组合简介中，为什么将w3设置为-1会取得完全错误的结果呢？


##编程练习
1.高维度线性模型可受益于使用一种基于梯度的优化方法，叫做 FTRL。该算法的优势是针对不同系数以不同方式调整学习速率，如果某些特征很少采用非零值，该算法可能比较实用（也非常适合支持 L1 正则化）。我们可以使用 FtrlOptimizer 来应用 FTRL。

2.离散特征的独热编码

通常，在训练逻辑回归模型之前，离散（即字符串、枚举、整数）特征会转换为二元特征系列。

例如，假设我们创建了一个合成特征，可以采用 `0`、`1` 或 `2` 中的任何值，并且我们还具有以下几个训练点：

| # | feature_value |
|---|---------------|
| 0 |             2 |
| 1 |             0 |
| 2 |             1 |

对于每个可能的分类值，我们都会创建一个新的**二元****实值**特征，该特征只能采用两个可能值中的一个：如果示例中包含该值，则值为 1.0；如果不包含，则值为 0.0。在上述示例中，分类特征会被转换成三个特征，现在训练点如下所示：

| # | feature_value_0 | feature_value_1 | feature_value_2 |
|---|-----------------|-----------------|-----------------|
| 0 |             0.0 |             0.0 |             1.0 |
| 1 |             1.0 |             0.0 |             0.0 |
| 2 |             0.0 |             1.0 |             0.0 |




